CUDA: True cuda:0
folder_dir: astgcn_r_h6d3w3_channel1_1.000000e-03
params_path: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03
create params directory experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03
param list:
CUDA	 cuda:0
in_channels	 1
nb_block	 2
nb_chev_filter	 64
nb_time_filter	 64
time_strides	 6
batch_size	 16
graph_signal_matrix_filename	 ./data/ManchesterHW/ManchesterHW_15.npz
start_epoch	 0
epochs	 100
ASTGCN_submodule(
  (BlockList): ModuleList(
    (0): ASTGCN_block(
      (TAt): Temporal_Attention_layer()
      (SAt): Spatial_Attention_layer()
      (cheb_conv_SAt): cheb_conv_withSAt(
        (Theta): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
        )
      )
      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 6), padding=(0, 1))
      (residual_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 6))
      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (1): ASTGCN_block(
      (TAt): Temporal_Attention_layer()
      (SAt): Spatial_Attention_layer()
      (cheb_conv_SAt): cheb_conv_withSAt(
        (Theta): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
        )
      )
      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (residual_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
  )
  (final_conv): Conv2d(2, 1, kernel_size=(1, 64), stride=(1, 1))
)
Net's state_dict:
BlockList.0.TAt.U1	torch.Size([1000])
BlockList.0.TAt.U2	torch.Size([1, 1000])
BlockList.0.TAt.U3	torch.Size([1])
BlockList.0.TAt.be	torch.Size([1, 12, 12])
BlockList.0.TAt.Ve	torch.Size([12, 12])
BlockList.0.SAt.W1	torch.Size([12])
BlockList.0.SAt.W2	torch.Size([1, 12])
BlockList.0.SAt.W3	torch.Size([1])
BlockList.0.SAt.bs	torch.Size([1, 1000, 1000])
BlockList.0.SAt.Vs	torch.Size([1000, 1000])
BlockList.0.cheb_conv_SAt.Theta.0	torch.Size([1, 64])
BlockList.0.cheb_conv_SAt.Theta.1	torch.Size([1, 64])
BlockList.0.cheb_conv_SAt.Theta.2	torch.Size([1, 64])
BlockList.0.time_conv.weight	torch.Size([64, 64, 1, 3])
BlockList.0.time_conv.bias	torch.Size([64])
BlockList.0.residual_conv.weight	torch.Size([64, 1, 1, 1])
BlockList.0.residual_conv.bias	torch.Size([64])
BlockList.0.ln.weight	torch.Size([64])
BlockList.0.ln.bias	torch.Size([64])
BlockList.1.TAt.U1	torch.Size([1000])
BlockList.1.TAt.U2	torch.Size([64, 1000])
BlockList.1.TAt.U3	torch.Size([64])
BlockList.1.TAt.be	torch.Size([1, 2, 2])
BlockList.1.TAt.Ve	torch.Size([2, 2])
BlockList.1.SAt.W1	torch.Size([2])
BlockList.1.SAt.W2	torch.Size([64, 2])
BlockList.1.SAt.W3	torch.Size([64])
BlockList.1.SAt.bs	torch.Size([1, 1000, 1000])
BlockList.1.SAt.Vs	torch.Size([1000, 1000])
BlockList.1.cheb_conv_SAt.Theta.0	torch.Size([64, 64])
BlockList.1.cheb_conv_SAt.Theta.1	torch.Size([64, 64])
BlockList.1.cheb_conv_SAt.Theta.2	torch.Size([64, 64])
BlockList.1.time_conv.weight	torch.Size([64, 64, 1, 3])
BlockList.1.time_conv.bias	torch.Size([64])
BlockList.1.residual_conv.weight	torch.Size([64, 64, 1, 1])
BlockList.1.residual_conv.bias	torch.Size([64])
BlockList.1.ln.weight	torch.Size([64])
BlockList.1.ln.bias	torch.Size([64])
final_conv.weight	torch.Size([1, 2, 1, 64])
final_conv.bias	torch.Size([1])
Net's total params: 4109437
Optimizer's state_dict:
state	{}
param_groups	[{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}]
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_0.params
global step: 1000, training loss: 83.62, time: 243.63s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_1.params
global step: 2000, training loss: 44.06, time: 487.51s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_2.params
global step: 3000, training loss: 37.31, time: 727.66s
global step: 4000, training loss: 25.13, time: 932.56s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_3.params
global step: 5000, training loss: 47.41, time: 1198.11s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_4.params
global step: 6000, training loss: 26.70, time: 1492.21s
global step: 7000, training loss: 28.46, time: 1760.90s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_5.params
global step: 8000, training loss: 57.53, time: 2051.45s
global step: 9000, training loss: 27.73, time: 2341.46s
global step: 10000, training loss: 35.72, time: 2610.78s
global step: 11000, training loss: 30.15, time: 2902.03s
global step: 12000, training loss: 29.15, time: 3193.04s
global step: 13000, training loss: 30.55, time: 3462.27s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_9.params
global step: 14000, training loss: 24.42, time: 3753.27s
global step: 15000, training loss: 25.03, time: 4043.42s
global step: 16000, training loss: 54.53, time: 4334.45s
global step: 17000, training loss: 29.13, time: 4603.51s
global step: 18000, training loss: 31.47, time: 4894.80s
global step: 19000, training loss: 53.04, time: 5185.69s
global step: 20000, training loss: 22.32, time: 5455.43s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_14.params
global step: 21000, training loss: 42.72, time: 5747.02s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_15.params
global step: 22000, training loss: 41.48, time: 6038.78s
global step: 23000, training loss: 34.49, time: 6295.21s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_16.params
global step: 24000, training loss: 31.71, time: 6519.96s
global step: 25000, training loss: 32.11, time: 6772.51s
global step: 26000, training loss: 24.16, time: 6979.21s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_18.params
global step: 27000, training loss: 22.00, time: 7204.51s
global step: 28000, training loss: 18.88, time: 7427.19s
global step: 29000, training loss: 34.77, time: 7648.06s
global step: 30000, training loss: 26.43, time: 7852.59s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_21.params
global step: 31000, training loss: 28.59, time: 8077.38s
global step: 32000, training loss: 24.40, time: 8331.96s
global step: 33000, training loss: 30.29, time: 8604.06s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_23.params
global step: 34000, training loss: 23.25, time: 8895.32s
global step: 35000, training loss: 23.67, time: 9186.56s
global step: 36000, training loss: 41.44, time: 9456.50s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_25.params
global step: 37000, training loss: 27.59, time: 9692.55s
global step: 38000, training loss: 21.41, time: 9966.50s
global step: 39000, training loss: 25.66, time: 10217.26s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_27.params
global step: 40000, training loss: 44.23, time: 10462.99s
global step: 41000, training loss: 21.23, time: 10737.76s
global step: 42000, training loss: 26.23, time: 11030.47s
global step: 43000, training loss: 17.85, time: 11300.75s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_30.params
global step: 44000, training loss: 26.22, time: 11598.13s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_31.params
global step: 45000, training loss: 18.00, time: 11889.51s
global step: 46000, training loss: 19.89, time: 12158.80s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_32.params
global step: 47000, training loss: 26.14, time: 12453.63s
global step: 48000, training loss: 19.21, time: 12749.48s
global step: 49000, training loss: 29.16, time: 13022.98s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_34.params
global step: 50000, training loss: 29.11, time: 13313.79s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_35.params
global step: 51000, training loss: 46.11, time: 13603.84s
global step: 52000, training loss: 22.63, time: 13874.35s
global step: 53000, training loss: 23.79, time: 14167.03s
global step: 54000, training loss: 27.85, time: 14459.90s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_38.params
global step: 55000, training loss: 23.84, time: 14752.44s
global step: 56000, training loss: 19.85, time: 15023.49s
global step: 57000, training loss: 21.45, time: 15316.38s
global step: 58000, training loss: 23.89, time: 15609.19s
global step: 59000, training loss: 25.45, time: 15878.92s
global step: 60000, training loss: 19.90, time: 16171.66s
global step: 61000, training loss: 19.37, time: 16465.01s
global step: 62000, training loss: 41.88, time: 16735.21s
global step: 63000, training loss: 24.44, time: 17026.40s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_44.params
global step: 64000, training loss: 20.25, time: 17318.81s
global step: 65000, training loss: 23.30, time: 17589.06s
global step: 66000, training loss: 19.90, time: 17881.00s
global step: 67000, training loss: 15.97, time: 18174.25s
global step: 68000, training loss: 24.13, time: 18466.12s
global step: 69000, training loss: 26.89, time: 18735.74s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_48.params
global step: 70000, training loss: 21.22, time: 19027.97s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_49.params
global step: 71000, training loss: 25.62, time: 19319.31s
global step: 72000, training loss: 18.72, time: 19589.98s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_50.params
global step: 73000, training loss: 23.65, time: 19882.06s
global step: 74000, training loss: 24.96, time: 20168.87s
global step: 75000, training loss: 27.99, time: 20438.89s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_52.params
global step: 76000, training loss: 19.48, time: 20731.36s
global step: 77000, training loss: 19.06, time: 21022.37s
global step: 78000, training loss: 22.55, time: 21292.22s
global step: 79000, training loss: 18.55, time: 21584.66s
global step: 80000, training loss: 20.85, time: 21876.30s
global step: 81000, training loss: 19.94, time: 22139.23s
global step: 82000, training loss: 23.88, time: 22365.52s
global step: 83000, training loss: 21.88, time: 22610.14s
global step: 84000, training loss: 19.65, time: 22854.59s
global step: 85000, training loss: 21.11, time: 23080.58s
global step: 86000, training loss: 17.23, time: 23325.81s
global step: 87000, training loss: 23.25, time: 23570.81s
global step: 88000, training loss: 22.56, time: 23796.89s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_61.params
global step: 89000, training loss: 25.74, time: 24041.87s
global step: 90000, training loss: 17.46, time: 24287.28s
global step: 91000, training loss: 21.90, time: 24513.22s
global step: 92000, training loss: 21.12, time: 24757.95s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_64.params
global step: 93000, training loss: 14.64, time: 25002.80s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_65.params
global step: 94000, training loss: 21.02, time: 25247.29s
global step: 95000, training loss: 21.05, time: 25472.95s
global step: 96000, training loss: 17.92, time: 25717.70s
global step: 97000, training loss: 18.80, time: 25962.45s
global step: 98000, training loss: 21.68, time: 26188.50s
global step: 99000, training loss: 20.31, time: 26432.98s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_69.params
global step: 100000, training loss: 23.85, time: 26677.60s
global step: 101000, training loss: 19.26, time: 26903.90s
global step: 102000, training loss: 21.00, time: 27148.12s
global step: 103000, training loss: 23.10, time: 27392.82s
global step: 104000, training loss: 16.49, time: 27618.51s
global step: 105000, training loss: 18.71, time: 27862.47s
global step: 106000, training loss: 20.72, time: 28106.90s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_74.params
global step: 107000, training loss: 17.42, time: 28351.30s
global step: 108000, training loss: 19.32, time: 28576.73s
global step: 109000, training loss: 16.61, time: 28820.23s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_76.params
global step: 110000, training loss: 16.80, time: 29063.87s
global step: 111000, training loss: 17.72, time: 29288.91s
global step: 112000, training loss: 19.67, time: 29533.00s
global step: 113000, training loss: 19.20, time: 29776.72s
global step: 114000, training loss: 19.53, time: 30001.92s
global step: 115000, training loss: 13.91, time: 30245.72s
global step: 116000, training loss: 16.93, time: 30489.34s
global step: 117000, training loss: 22.07, time: 30714.72s
global step: 118000, training loss: 23.54, time: 30958.23s
global step: 119000, training loss: 18.29, time: 31201.48s
global step: 120000, training loss: 19.41, time: 31444.69s
global step: 121000, training loss: 21.14, time: 31670.04s
global step: 122000, training loss: 19.22, time: 31913.71s
global step: 123000, training loss: 20.66, time: 32157.54s
global step: 124000, training loss: 20.26, time: 32382.68s
global step: 125000, training loss: 20.07, time: 32626.21s
global step: 126000, training loss: 15.89, time: 32869.86s
global step: 127000, training loss: 22.05, time: 33094.97s
global step: 128000, training loss: 19.37, time: 33338.46s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_89.params
global step: 129000, training loss: 20.35, time: 33582.15s
global step: 130000, training loss: 22.92, time: 33807.56s
global step: 131000, training loss: 16.78, time: 34051.24s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_91.params
global step: 132000, training loss: 17.71, time: 34294.77s
global step: 133000, training loss: 17.54, time: 34538.34s
global step: 134000, training loss: 14.41, time: 34763.48s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_93.params
global step: 135000, training loss: 15.81, time: 35006.91s
global step: 136000, training loss: 19.69, time: 35250.21s
global step: 137000, training loss: 20.68, time: 35474.92s
global step: 138000, training loss: 15.84, time: 35718.48s
global step: 139000, training loss: 19.58, time: 35961.87s
global step: 140000, training loss: 19.29, time: 36186.49s
global step: 141000, training loss: 19.72, time: 36429.74s
save parameters to file: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_98.params
global step: 142000, training loss: 17.05, time: 36673.08s
global step: 143000, training loss: 15.19, time: 36897.99s
global step: 144000, training loss: 19.49, time: 37141.24s
best epoch: 98
load weight from: experiments\ManchesterHW_15\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_98.params
predicting data set batch 1 / 413
predicting data set batch 101 / 413
predicting data set batch 201 / 413
predicting data set batch 301 / 413
predicting data set batch 401 / 413
input: (6605, 1000, 1, 12)
prediction: (6605, 1000, 1)
data_target_tensor: (6605, 1000, 1)
current epoch: 98, predict 0 points
MAE: 24.22
RMSE: 46.93
MAPE: 0.35
all MAE: 24.22
all RMSE: 46.93
all MAPE: 0.35
[24.224827, 46.932198, 0.35261306, 24.224827, 46.932198, 0.35261306]
