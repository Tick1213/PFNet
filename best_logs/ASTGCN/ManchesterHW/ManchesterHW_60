CUDA: True cuda:0
folder_dir: astgcn_r_h6d3w3_channel1_1.000000e-03
params_path: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03
create params directory experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03
param list:
CUDA	 cuda:0
in_channels	 1
nb_block	 2
nb_chev_filter	 64
nb_time_filter	 64
time_strides	 6
batch_size	 16
graph_signal_matrix_filename	 ./data/ManchesterHW/ManchesterHW_60.npz
start_epoch	 0
epochs	 400
ASTGCN_submodule(
  (BlockList): ModuleList(
    (0): ASTGCN_block(
      (TAt): Temporal_Attention_layer()
      (SAt): Spatial_Attention_layer()
      (cheb_conv_SAt): cheb_conv_withSAt(
        (Theta): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
        )
      )
      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 6), padding=(0, 1))
      (residual_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 6))
      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (1): ASTGCN_block(
      (TAt): Temporal_Attention_layer()
      (SAt): Spatial_Attention_layer()
      (cheb_conv_SAt): cheb_conv_withSAt(
        (Theta): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
        )
      )
      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (residual_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
  )
  (final_conv): Conv2d(2, 1, kernel_size=(1, 64), stride=(1, 1))
)
Net's state_dict:
BlockList.0.TAt.U1	torch.Size([1000])
BlockList.0.TAt.U2	torch.Size([1, 1000])
BlockList.0.TAt.U3	torch.Size([1])
BlockList.0.TAt.be	torch.Size([1, 12, 12])
BlockList.0.TAt.Ve	torch.Size([12, 12])
BlockList.0.SAt.W1	torch.Size([12])
BlockList.0.SAt.W2	torch.Size([1, 12])
BlockList.0.SAt.W3	torch.Size([1])
BlockList.0.SAt.bs	torch.Size([1, 1000, 1000])
BlockList.0.SAt.Vs	torch.Size([1000, 1000])
BlockList.0.cheb_conv_SAt.Theta.0	torch.Size([1, 64])
BlockList.0.cheb_conv_SAt.Theta.1	torch.Size([1, 64])
BlockList.0.cheb_conv_SAt.Theta.2	torch.Size([1, 64])
BlockList.0.time_conv.weight	torch.Size([64, 64, 1, 3])
BlockList.0.time_conv.bias	torch.Size([64])
BlockList.0.residual_conv.weight	torch.Size([64, 1, 1, 1])
BlockList.0.residual_conv.bias	torch.Size([64])
BlockList.0.ln.weight	torch.Size([64])
BlockList.0.ln.bias	torch.Size([64])
BlockList.1.TAt.U1	torch.Size([1000])
BlockList.1.TAt.U2	torch.Size([64, 1000])
BlockList.1.TAt.U3	torch.Size([64])
BlockList.1.TAt.be	torch.Size([1, 2, 2])
BlockList.1.TAt.Ve	torch.Size([2, 2])
BlockList.1.SAt.W1	torch.Size([2])
BlockList.1.SAt.W2	torch.Size([64, 2])
BlockList.1.SAt.W3	torch.Size([64])
BlockList.1.SAt.bs	torch.Size([1, 1000, 1000])
BlockList.1.SAt.Vs	torch.Size([1000, 1000])
BlockList.1.cheb_conv_SAt.Theta.0	torch.Size([64, 64])
BlockList.1.cheb_conv_SAt.Theta.1	torch.Size([64, 64])
BlockList.1.cheb_conv_SAt.Theta.2	torch.Size([64, 64])
BlockList.1.time_conv.weight	torch.Size([64, 64, 1, 3])
BlockList.1.time_conv.bias	torch.Size([64])
BlockList.1.residual_conv.weight	torch.Size([64, 64, 1, 1])
BlockList.1.residual_conv.bias	torch.Size([64])
BlockList.1.ln.weight	torch.Size([64])
BlockList.1.ln.bias	torch.Size([64])
final_conv.weight	torch.Size([1, 2, 1, 64])
final_conv.bias	torch.Size([1])
Net's total params: 4109437
Optimizer's state_dict:
state	{}
param_groups	[{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}]
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_0.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_1.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_2.params
global step: 1000, training loss: 600.73, time: 231.52s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_3.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_4.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_5.params
global step: 2000, training loss: 352.50, time: 452.90s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_6.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_7.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_8.params
global step: 3000, training loss: 175.32, time: 676.99s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_9.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_10.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_11.params
global step: 4000, training loss: 138.89, time: 895.10s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_12.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_13.params
global step: 5000, training loss: 108.67, time: 1360.84s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_14.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_15.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_16.params
global step: 6000, training loss: 109.01, time: 1584.80s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_17.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_18.params
global step: 7000, training loss: 159.23, time: 1812.80s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_21.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_22.params
global step: 8000, training loss: 100.22, time: 2038.67s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_23.params
global step: 9000, training loss: 97.95, time: 2260.06s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_25.params
global step: 10000, training loss: 88.01, time: 2483.95s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_29.params
global step: 11000, training loss: 95.82, time: 2702.35s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_32.params
global step: 12000, training loss: 94.03, time: 2917.93s
global step: 13000, training loss: 119.02, time: 3129.10s
global step: 14000, training loss: 91.23, time: 3345.50s
global step: 15000, training loss: 146.42, time: 3562.76s
global step: 16000, training loss: 78.73, time: 3777.87s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_45.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_46.params
global step: 17000, training loss: 87.43, time: 3989.35s
global step: 18000, training loss: 175.41, time: 4205.97s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_51.params
global step: 19000, training loss: 90.89, time: 4424.66s
global step: 20000, training loss: 91.01, time: 4641.43s
global step: 21000, training loss: 71.76, time: 4856.60s
global step: 22000, training loss: 77.55, time: 5068.37s
global step: 23000, training loss: 117.29, time: 5284.07s
global step: 24000, training loss: 109.68, time: 5498.91s
global step: 25000, training loss: 152.54, time: 5713.63s
global step: 26000, training loss: 100.69, time: 5946.75s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_72.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_73.params
global step: 27000, training loss: 96.77, time: 6185.54s
global step: 28000, training loss: 96.66, time: 6424.34s
global step: 29000, training loss: 93.39, time: 6662.39s
global step: 30000, training loss: 91.45, time: 6895.71s
global step: 31000, training loss: 85.96, time: 7134.21s
global step: 32000, training loss: 88.17, time: 7359.66s
global step: 33000, training loss: 88.76, time: 7597.28s
global step: 34000, training loss: 119.23, time: 7822.62s
global step: 35000, training loss: 79.40, time: 8038.27s
global step: 36000, training loss: 104.34, time: 8254.10s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_102.params
global step: 37000, training loss: 126.45, time: 8469.80s
global step: 38000, training loss: 79.78, time: 8681.31s
global step: 39000, training loss: 96.71, time: 8896.95s
global step: 40000, training loss: 120.54, time: 9112.28s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_112.params
global step: 41000, training loss: 108.43, time: 9327.05s
global step: 42000, training loss: 122.67, time: 9542.29s
global step: 43000, training loss: 70.25, time: 9753.21s
global step: 44000, training loss: 89.59, time: 9968.97s
global step: 45000, training loss: 91.05, time: 10184.00s
global step: 46000, training loss: 74.84, time: 10398.81s
global step: 47000, training loss: 84.28, time: 10611.05s
global step: 48000, training loss: 69.85, time: 10826.57s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_134.params
global step: 49000, training loss: 76.50, time: 11042.03s
global step: 50000, training loss: 59.78, time: 11257.93s
global step: 51000, training loss: 92.60, time: 11469.68s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_141.params
global step: 52000, training loss: 69.95, time: 11684.92s
global step: 53000, training loss: 90.47, time: 11909.32s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_147.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_148.params
global step: 54000, training loss: 79.43, time: 12147.44s
global step: 55000, training loss: 81.81, time: 12380.90s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_152.params
global step: 56000, training loss: 70.54, time: 12618.74s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_156.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_157.params
global step: 57000, training loss: 82.49, time: 12856.61s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_159.params
global step: 58000, training loss: 66.39, time: 13094.58s
global step: 59000, training loss: 73.34, time: 13327.86s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_163.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_164.params
global step: 60000, training loss: 67.98, time: 13565.66s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_168.params
global step: 61000, training loss: 64.87, time: 13803.82s
global step: 62000, training loss: 87.47, time: 14041.79s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_173.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_174.params
global step: 63000, training loss: 66.50, time: 14279.86s
global step: 64000, training loss: 64.86, time: 14513.13s
global step: 65000, training loss: 132.62, time: 14750.94s
global step: 66000, training loss: 55.40, time: 14988.77s
global step: 67000, training loss: 71.08, time: 15226.81s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_186.params
global step: 68000, training loss: 58.24, time: 15460.42s
global step: 69000, training loss: 50.52, time: 15698.40s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_192.params
global step: 70000, training loss: 78.41, time: 15936.23s
global step: 71000, training loss: 62.95, time: 16173.92s
global step: 72000, training loss: 52.34, time: 16407.14s
global step: 73000, training loss: 54.65, time: 16645.08s
global step: 74000, training loss: 46.30, time: 16882.91s
global step: 75000, training loss: 47.88, time: 17120.75s
global step: 76000, training loss: 69.85, time: 17354.35s
global step: 77000, training loss: 58.74, time: 17592.30s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_215.params
global step: 78000, training loss: 49.99, time: 17830.26s
global step: 79000, training loss: 71.84, time: 18068.03s
global step: 80000, training loss: 47.56, time: 18301.37s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_221.params
global step: 81000, training loss: 66.91, time: 18539.57s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_225.params
global step: 82000, training loss: 42.35, time: 18777.63s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_227.params
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_229.params
global step: 83000, training loss: 59.10, time: 19015.58s
global step: 84000, training loss: 48.45, time: 19253.60s
global step: 85000, training loss: 57.23, time: 19487.26s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_236.params
global step: 86000, training loss: 59.09, time: 19725.09s
global step: 87000, training loss: 60.19, time: 19963.01s
global step: 88000, training loss: 65.78, time: 20200.97s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_244.params
global step: 89000, training loss: 53.67, time: 20434.52s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_248.params
global step: 90000, training loss: 56.53, time: 20672.56s
global step: 91000, training loss: 59.50, time: 20910.32s
global step: 92000, training loss: 50.47, time: 21148.16s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_256.params
global step: 93000, training loss: 52.41, time: 21381.60s
global step: 94000, training loss: 53.22, time: 21619.47s
global step: 95000, training loss: 52.10, time: 21857.45s
global step: 96000, training loss: 46.72, time: 22095.73s
global step: 97000, training loss: 65.48, time: 22313.28s
global step: 98000, training loss: 41.88, time: 22533.43s
global step: 99000, training loss: 57.97, time: 22752.94s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_275.params
global step: 100000, training loss: 45.40, time: 22975.83s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_279.params
global step: 101000, training loss: 49.28, time: 23199.51s
global step: 102000, training loss: 51.59, time: 23494.92s
global step: 103000, training loss: 55.38, time: 23717.51s
global step: 104000, training loss: 48.84, time: 23971.70s
global step: 105000, training loss: 63.42, time: 24193.87s
global step: 106000, training loss: 43.36, time: 24410.74s
global step: 107000, training loss: 42.80, time: 24636.83s
global step: 108000, training loss: 53.39, time: 24859.44s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_301.params
global step: 109000, training loss: 39.53, time: 25074.34s
global step: 110000, training loss: 45.62, time: 25285.42s
global step: 111000, training loss: 54.67, time: 25500.85s
global step: 112000, training loss: 50.12, time: 25716.06s
global step: 113000, training loss: 53.93, time: 25931.31s
global step: 114000, training loss: 48.61, time: 26143.00s
global step: 115000, training loss: 42.81, time: 26360.14s
global step: 116000, training loss: 47.26, time: 26575.91s
global step: 117000, training loss: 47.79, time: 26793.71s
global step: 118000, training loss: 40.68, time: 27076.72s
global step: 119000, training loss: 47.11, time: 27342.06s
global step: 120000, training loss: 40.28, time: 27557.39s
global step: 121000, training loss: 54.82, time: 27773.17s
global step: 122000, training loss: 49.97, time: 28001.23s
global step: 123000, training loss: 50.28, time: 28228.06s
global step: 124000, training loss: 49.81, time: 28457.72s
global step: 125000, training loss: 43.99, time: 28686.36s
global step: 126000, training loss: 40.72, time: 28912.43s
global step: 127000, training loss: 39.81, time: 29133.84s
global step: 128000, training loss: 47.13, time: 29364.30s
global step: 129000, training loss: 54.41, time: 29597.61s
global step: 130000, training loss: 45.96, time: 29829.75s
global step: 131000, training loss: 48.19, time: 30048.98s
global step: 132000, training loss: 47.88, time: 30276.35s
global step: 133000, training loss: 54.42, time: 30524.11s
global step: 134000, training loss: 37.57, time: 30771.50s
global step: 135000, training loss: 42.90, time: 31014.68s
global step: 136000, training loss: 47.92, time: 31262.60s
global step: 137000, training loss: 51.77, time: 31510.48s
global step: 138000, training loss: 44.90, time: 31758.23s
global step: 139000, training loss: 41.20, time: 31993.23s
global step: 140000, training loss: 35.11, time: 32232.55s
save parameters to file: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_389.params
global step: 141000, training loss: 40.40, time: 32467.91s
global step: 142000, training loss: 42.20, time: 32684.39s
global step: 143000, training loss: 43.08, time: 32900.95s
global step: 144000, training loss: 38.14, time: 33113.81s
best epoch: 389
load weight from: experiments\ManchesterHW_60\astgcn_r_h6d3w3_channel1_1.000000e-03\epoch_389.params
predicting data set batch 1 / 104
predicting data set batch 101 / 104
input: (1652, 1000, 1, 12)
prediction: (1652, 1000, 1)
data_target_tensor: (1652, 1000, 1)
current epoch: 389, predict 0 points
MAE: 74.22
RMSE: 139.64
MAPE: 0.28
all MAE: 74.22
all RMSE: 139.64
all MAPE: 0.28
[74.2153, 139.63762, 0.2826486, 74.2153, 139.63762, 0.2826486]
