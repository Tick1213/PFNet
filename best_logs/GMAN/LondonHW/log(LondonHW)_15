K=8, L=1, P=12, Q=1, SE_file='data/SE1.txt', batch_size=2, d=8, decay_epoch=5, learning_rate=0.001, log_file='data/log(LondonHW)_15', max_epoch=1000, model_file='data/GMAN(LondonHW)_15', patience=10, test_ratio=0.2, time_slot=15, traffic_file='data/LondonHW_15.h5', train_ratio=0.7, val_ratio=0.1
loading data...
trainX: (24516, 12, 1000)	trainY: (24516, 1, 1000)
valX:   (3492, 12, 1000)		valY:   (3492, 1, 1000)
testX:  (6996, 12, 1000)		testY:  (6996, 1, 1000)
data loaded!
compiling model...
trainable parameters: 217,281
model compiled!
**** training model ****
2022-04-03 18:51:06 | epoch: 0001/1000, training time: 1634.8s, inference time: 65.9s
train loss: 53.8347, val_loss: 67.0683
val loss decrease from inf to 67.0683, saving model to data/GMAN(LondonHW)_15
2022-04-03 19:19:11 | epoch: 0002/1000, training time: 1616.6s, inference time: 63.2s
train loss: 38.2337, val_loss: 95.5917
2022-04-03 19:46:27 | epoch: 0003/1000, training time: 1572.6s, inference time: 62.7s
train loss: 35.0352, val_loss: 75.7597
2022-04-03 20:14:03 | epoch: 0004/1000, training time: 1590.8s, inference time: 64.7s
train loss: 33.2015, val_loss: 38.7890
val loss decrease from 67.0683 to 38.7890, saving model to data/GMAN(LondonHW)_15
2022-04-03 20:42:14 | epoch: 0005/1000, training time: 1621.6s, inference time: 64.6s
train loss: 32.2218, val_loss: 35.2205
val loss decrease from 38.7890 to 35.2205, saving model to data/GMAN(LondonHW)_15
2022-04-03 21:10:27 | epoch: 0006/1000, training time: 1623.5s, inference time: 64.6s
train loss: 30.4545, val_loss: 40.0354
2022-04-03 21:38:24 | epoch: 0007/1000, training time: 1612.2s, inference time: 64.7s
train loss: 29.9121, val_loss: 44.5157
2022-04-03 22:06:38 | epoch: 0008/1000, training time: 1627.2s, inference time: 65.4s
train loss: 29.6413, val_loss: 42.6628
2022-04-03 22:34:53 | epoch: 0009/1000, training time: 1629.1s, inference time: 65.3s
train loss: 29.3519, val_loss: 52.4915
2022-04-03 23:02:50 | epoch: 0010/1000, training time: 1611.9s, inference time: 64.6s
train loss: 29.1082, val_loss: 41.2901
2022-04-03 23:30:56 | epoch: 0011/1000, training time: 1620.2s, inference time: 65.5s
train loss: 28.3268, val_loss: 36.0811
2022-04-03 23:58:59 | epoch: 0012/1000, training time: 1618.4s, inference time: 64.6s
train loss: 28.1746, val_loss: 39.9606
2022-04-04 00:27:02 | epoch: 0013/1000, training time: 1618.3s, inference time: 63.2s
train loss: 27.9830, val_loss: 39.4042
2022-04-04 00:54:21 | epoch: 0014/1000, training time: 1575.9s, inference time: 62.8s
train loss: 27.8786, val_loss: 36.4233
2022-04-04 01:21:41 | epoch: 0015/1000, training time: 1577.4s, inference time: 62.7s
train loss: 27.7686, val_loss: 42.7610
early stop at epoch: 0015
**** testing model ****
loading model from data/GMAN(LondonHW)_15
model restored!
evaluating...
testing time: 125.7s
                MAE		RMSE		MAPE
train            34.48		53.69		37.34%
val              35.22		55.03		36.00%
test             33.54		52.25		38.40%
performance in each prediction step
step: 01         33.54		52.25		38.40%
average:         33.54		52.25		38.40%
total time: 429.7min
